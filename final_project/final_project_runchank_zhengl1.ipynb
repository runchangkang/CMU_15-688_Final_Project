{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA GAME PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Project for 15-688 Practical Data Science\n",
    "#### Authors: Runchang Kang / Zheng Luo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The charming part of sport games must be the unpredictability. Countless of buzzer beaters and upsets not only crazied the fans, but also raised human's curiosity to use machine to predict the result. As basketball fans and students who just took the practical data science course, we can't wait to use the knowledge and skillsets that learnt from the course to play with the \"mistical power\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Content\n",
    "\n",
    "In this project, we will show the pipeline of using data science techniques to play with data and try to get the best prediction as we can. The main structure of the project includes:\n",
    "- [Data Collection](#Data-Collection)\n",
    "- [Data Processing](#Data-Processing)\n",
    "- [Model Selection](#Model-Selection)\n",
    "- [Training and Prediction](#Training-and-Prediction)\n",
    "- [Iteration and Adjustment](#Iteration-and-Adjustment)\n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although many datasets already exist online, many of them are poorly structured and hard to utilize. We decide to scrape the raw data from a NBA statistic website [https://www.basketball-reference.com/] The website has documented every single game orderly so it won't be too hard to get the data we need. \n",
    "\n",
    "Before starting scraping the website, we have to think about what kind of data we need and how the data will be structured locally. After a heated discussion, we figured out there is no perfect way to do the prediction. Due to the large number of poteintial influential factors, such as, the player's physical and emotional state, the team chemistry, the strength of schedule, the home or road game factor, the influence from social media, the player's fluctuation during the game, and so on. We have to admit the existence of bias.\n",
    "\n",
    "We planned to collect the statistic data of each game each team from 1995 to 2017, and use the mean of previous `5 games' data` to represent the general status of a team. However, due to the opponents of previous five games are different, we assume that the mean will neutralize the difference of level of those opponents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scrape all teams all games statistic from 1995 to 2017. However, some teams changed their name or location within the year, we have to carefully process these data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utlis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEAM_NAMES=[\"ATL\",\"BOS\",\"BRK\",\"NJN\",\"CHA\",\"CHH\",\"CHO\",\"CHI\",\"CLE\",\"DAL\",\"DEN\",\"DET\",\"GSW\",\"HOU\",\"IND\",\"LAC\",\"LAL\",\"MEM\",\"VAN\",\"MIA\",\"MIL\",\"MIN\",\"NOP\",\"NOH\",\"NOK\",\"NYK\",\"OKC\",\"SEA\",\"ORL\",\"PHI\",\"PHO\",\"POR\",\"SAC\",\"SAS\",\"TOR\",\"UTA\", \"WSB\",\"WAS\"]\n",
    "YEARS=[\"%s\" %x for x in range(1995,2017)]\n",
    "BASE_TEAM_URL= \"https://www.basketball-reference.com/teams\"\n",
    "#several teams have multiple names\n",
    "TEAM_INDEX={\"ATL\":0,\n",
    " \"BOS\":1,\n",
    " \"BRK\":2,\"NJN\":2,\n",
    " \"CHA\":3,\"CHH\":3,\"CHO\":3,\n",
    " \"CHI\":4,\n",
    " \"CLE\":5,\n",
    " \"DAL\":6,\n",
    " \"DEN\":7,\n",
    " \"DET\":8,\n",
    " \"GSW\":9,\n",
    " \"HOU\":10,\n",
    " \"IND\":11,\n",
    " \"LAC\":12,\n",
    " \"LAL\":13,\n",
    " \"MEM\":14,\"VAN\":14,\n",
    " \"MIA\":15,\n",
    " \"MIL\":16,\n",
    " \"MIN\":17,\n",
    " \"NOH\":18,\"NOK\":18,\"NOP\":18,\n",
    " \"NYK\":19,\n",
    " \"SEA\":20,\"OKC\":20,\n",
    " \"ORL\":21,\n",
    " \"PHI\":22,\n",
    " \"PHO\":23,\n",
    " \"POR\":24,\n",
    " \"SAC\":25,\n",
    " \"SAS\":26,\n",
    " \"TOR\":27,\n",
    " \"UTA\":28,\n",
    " \"WSB\":29,\"WAS\":29}\n",
    "\n",
    "#this function helps create structural dataframe for each team\n",
    "#we store the data as pickle file for each team\n",
    "def createNewDataframes():\n",
    "    return (pd.DataFrame(columns = [\"teamIndex\",\"oppoIndex\",\"gameDate\",\"result\",\"FG\",\"FGA\",\"3P\",\"3PA\",\"FT\",\"FTA\",\"ORB\",\"DRB\",\"AST\",\"STL\",\"BLK\",\"TOV\",\"PF\",\"PTS\"]),\n",
    "           pd.DataFrame(columns = [\"teamIndex\",\"oppoIndex\",\"gameDate\",\"result\",\"TS%\",\"eFG%\",\"3PAr\",\"FTr\",\"ORB%\",\"DRB%\",\"TRB%\",\"AST%\",\"STL%\",\"BLK%\",\"TOV%\",\"USB%\",\"ORtg\",\"DRtg\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping\n",
    "\n",
    "The scaping took about four hours to run. We seperated the works into 3 laptops and stored all the data as pickle file which named by team.\n",
    "\n",
    "We store the following features of each game:\n",
    "\n",
    "-`FG : Field Goal`\n",
    "\n",
    "-`FGA : Filed Goal Atempts`\n",
    "\n",
    "-`3P : 3-points Filed Goal`\n",
    "\n",
    "-`3PA : 3-points Filed Goal Atempts`\n",
    "\n",
    "-`FT : Free Throw`\n",
    "\n",
    "-`FTA : Free Throw Atempts`\n",
    "\n",
    "-`ORB : Offence Rebound `\n",
    "\n",
    "-`DRB : Defence Rebound `\n",
    "\n",
    "-`AST : Assists`\n",
    "\n",
    "-`STL : Steals`\n",
    "\n",
    "-`BLK : Block Shot `\n",
    "\n",
    "-`TOV : Turnovers`\n",
    "\n",
    "-`PF : Personal Fouls`\n",
    "\n",
    "-`PTS : Points`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function will scape and store the data as pickle files for each team\n",
    "def scape_data(TEAM_NAMES,YEARS, BASE_TEAM_URL):\n",
    "    for team in TEAM_NAMES:\n",
    "        basicDf,advancedDf = createNewDataframes()\n",
    "        for year in YEARS:\n",
    "            url = BASE_TEAM_URL +\"/\"+team+\"/\"+year+\"_games.html\"\n",
    "            print(url)\n",
    "            response = requests.get(url)\n",
    "            root = BeautifulSoup(response.text,\"html5lib\")\n",
    "            items = root.find_all(\"td\",attrs={\"data-stat\": \"box_score_text\",\"class\":\"center\"})\n",
    "            winList = []\n",
    "            if items == None:\n",
    "                continue\n",
    "            #get game results\n",
    "            winItems = root.find_all(\"td\",attrs={\"data-stat\": \"game_result\",\"class\":\"center\"})\n",
    "            winList = []\n",
    "            for i in winItems:\n",
    "                if i.text==\"W\":\n",
    "                    winList.append(1)\n",
    "                elif i.text ==\"L\":\n",
    "                    winList.append(0)\n",
    "\n",
    "            if len(items)!= len(winList):\n",
    "                print(\"mismatch!\")\n",
    "            #get opponents:\n",
    "            oppoList = []\n",
    "            oppoItems = root.find_all(\"td\",attrs={\"data-stat\": \"opp_name\",\"class\":\"left\"})\n",
    "\n",
    "\n",
    "            for i in oppoItems:\n",
    "                tmp = i[\"csk\"][:3]\n",
    "                if tmp != None:\n",
    "                    oppoList.append(tmp)\n",
    "                else:\n",
    "                    print(\"here is a None!\")\n",
    "\n",
    "            if len(items)!= len(winList):\n",
    "                print(\"mismatch!\")\n",
    "            for index,item in enumerate(items):\n",
    "                newUrl = BASE_TEAM_URL[:-6]+item.a[\"href\"]\n",
    "                date = item.a[\"href\"][11:19]\n",
    "                basicList = [TEAM_INDEX[team],TEAM_INDEX[oppoList[index]],date,winList[index]]\n",
    "                advancedList = [TEAM_INDEX[team],TEAM_INDEX[oppoList[index]],date,winList[index]]\n",
    "                newResponse = requests.get(newUrl)\n",
    "                tmpRoot = BeautifulSoup(newResponse.text,\"html5lib\")\n",
    "                idString = \"all_box_%s_basic\" % team.lower()\n",
    "                tmpItem = tmpRoot.find(\"div\",attrs={\"id\":idString}).find(\"tfoot\")\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"fg\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"fga\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"fg3\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"fg3a\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"ft\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"fta\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"orb\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"drb\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"ast\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"stl\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"blk\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"tov\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"pf\"}).text)\n",
    "                basicList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"pts\"}).text)\n",
    "                basicDf.loc[basicDf.shape[0]] = basicList\n",
    "\n",
    "\n",
    "                idString = \"all_box_%s_advanced\" % team.lower()\n",
    "                tmpItem = tmpRoot.find(\"div\",attrs={\"id\":idString}).find(\"tfoot\")\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"ts_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"efg_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"fg3a_per_fga_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"fta_per_fga_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"orb_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"drb_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"trb_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"ast_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"stl_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"blk_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"tov_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"usg_pct\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"off_rtg\"}).text)\n",
    "                advancedList.append(tmpItem.find(\"td\",attrs={\"data-stat\":\"def_rtg\"}).text)\n",
    "                advancedDf.loc[advancedDf.shape[0]] = advancedList\n",
    "            basicName = \"%s_basic_data.pickle\"%team\n",
    "            advancedName = \"%s_advanced_data.pickle\"%team\n",
    "            basicDf.to_pickle(basicName)\n",
    "            advancedDf.to_pickle(advancedName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utlis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#manipulate the dataframe into right data type\n",
    "def changeDtypes(df):\n",
    "    df['gameDate'] = pd.to_datetime(df['gameDate'], format=\"%Y%m%d\")\n",
    "    for i in df.columns:\n",
    "        if i not in ('teamIndex','gameDate','result',\"oppoIndex\"):\n",
    "            df[i]=df[i].astype(\"float64\") \n",
    "        \n",
    "    return df\n",
    "\n",
    "#calculate the mean of previous k games,ignore the columns in a\n",
    "#adding one more row of previous result's mean\n",
    "def refactorDF2(df,k,a):\n",
    "    newDf = df.copy()\n",
    "    for i in range(k,df.shape[0]):\n",
    "        \n",
    "        for column in a:\n",
    "            newDf.at[i,column] = df.iloc[i-k:i-1][column].mean() \n",
    "        newDf.at[i,\"preResult\"] = df.iloc[i-k:i-1][\"result\"].astype(\"float64\").mean() \n",
    "    return newDf.iloc[k:]\n",
    "\n",
    "#calculate the mean of previous k games,ignore the columns in a\n",
    "#adding one more row of previous result's mean\n",
    "def refactorDF(df,k,a):\n",
    "    newDf = df.copy()\n",
    "    for i in range(k,df.shape[0]):\n",
    "        \n",
    "        for column in a:\n",
    "            newDf.at[i,column] = df.iloc[i-k:i-1][column].mean() \n",
    "        \n",
    "    return newDf.iloc[k:]\n",
    "#get the column names that need to process\n",
    "def getBasicColumnList(df):\n",
    "    a=list(df.columns)\n",
    "    for i in ['teamIndex','gameDate','result',\"oppoIndex\",\"preResult\"]:\n",
    "        a.remove(i)\n",
    "    return a\n",
    "#get the column names that need to process\n",
    "def getBasicColumnList2(df):\n",
    "    a=list(df.columns)\n",
    "    for i in ['teamIndex','gameDate','result',\"oppoIndex\"]:\n",
    "        a.remove(i)\n",
    "    return a\n",
    "#helper function for adding the up to date seasonal win records\n",
    "def compareDate(df):\n",
    "    newDf = df.copy()\n",
    "    DELTALimit = datetime.timedelta(weeks=16)\n",
    "    newDf.at[0,\"preResult\"] = 0\n",
    "    newSeasonIndex = 0\n",
    "    for i in range(1,df.shape[0]):\n",
    "        delta = newDf.at[i,\"gameDate\"]- newDf.at[i-1,\"gameDate\"]\n",
    "        \n",
    "        if delta < DELTALimit:\n",
    "            newDf.at[i,\"preResult\"] = df.iloc[newSeasonIndex:i][\"result\"].astype(\"float64\").sum()/(i-newSeasonIndex)\n",
    "        else:\n",
    "            \n",
    "            newSeasonIndex = i\n",
    "            newDf.at[i,\"preResult\"] = 0\n",
    "    return newDf\n",
    "\n",
    "\n",
    "basicDataFileNames = [\"%s_basic_data.pickle\"%x for x in TEAM_INDEX]\n",
    "advancedDataFileNames = [\"%s_advanced_data.pickle\"%x for x in TEAM_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this function combine all of the data that we scraped form the stat website\n",
    "#including considering the changed of team names\n",
    "#it takes some time to process, I store them in a file\n",
    "def combineData(DataFileNames,k=5):\n",
    "    dataFrameSet = dict()\n",
    "    for fileName in DataFileNames:\n",
    "        df = pd.read_pickle(fileName)\n",
    "        df = changeDtypes(df)\n",
    "        df = compareDate(df)\n",
    "        df = refactorDF(df,k,ignoreCol)\n",
    "        \n",
    "        curIndex = df.iloc[0][\"teamIndex\"]\n",
    "        if curIndex not in dataFrameSet:\n",
    "            dataFrameSet[curIndex] = df\n",
    "        else:\n",
    "            dataFrameSet[curIndex] = pd.concat([dataFrameSet[curIndex],df])\n",
    "    return dataFrameSet\n",
    "\n",
    "\n",
    "dataFrameSet = combineData(advancedDataFileNames)\n",
    "\n",
    "with open(\"join_data.pickle\",\"wb\") as f:\n",
    "    pickle.dump(dataFrameSet,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this function create all of the features in the dataframe and output as \n",
    "#numpy array\n",
    "def createTheFeatures(dataFrameSet,ignoreCol):\n",
    "    finalArray = np.array([])\n",
    "    flag = True\n",
    "    yValue = np.array([])\n",
    "    for key in dataFrameSet:\n",
    "        df = dataFrameSet[key]\n",
    "        \n",
    "        for i in range(df.shape[0]):\n",
    "            tmpArray = df.iloc[i][ignoreCol].values\n",
    "            tmpArray = tmpArray.reshape(1,tmpArray.shape[0])\n",
    "            if np.isnan(np.min(tmpArray)):\n",
    "                continue\n",
    "            oppoDf = dataFrameSet[df.iloc[i][\"oppoIndex\"]]\n",
    "            time = df.iloc[i][\"gameDate\"]\n",
    "            oppoRow = oppoDf.loc[oppoDf[\"gameDate\"]==time]\n",
    "            if not oppoRow.empty:\n",
    "                \n",
    "                oppoArray = oppoRow[ignoreCol].values\n",
    "                if np.isnan(np.min(oppoArray)):\n",
    "                    continue\n",
    "                tmpArray = np.append(tmpArray,oppoArray)\n",
    "                if flag:\n",
    "                    finalArray = tmpArray\n",
    "                    flag = False\n",
    "                else:   \n",
    "                    finalArray = np.vstack((finalArray,tmpArray))\n",
    "                yValue = np.append(yValue,df.iloc[i][\"result\"])\n",
    "                print(finalArray.shape)\n",
    "                print(yValue.shape)\n",
    "    return finalArray,yValue\n",
    "\n",
    "\n",
    "with open(\"join_data.pickle\",\"rb\") as f:\n",
    "    dataFrameSet=pickle.load(f)\n",
    "ignoreCol = getBasicColumnList2(dataFrameSet[0])\n",
    "X,y = createTheFeatures(dataFrameSet,ignoreCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store the data into files\n",
    "with open(\"X_ad3.pickle\",\"wb\") as f:\n",
    "    pickle.dump(X,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "with open(\"y_ad3.pickle\",\"wb\") as f:\n",
    "    pickle.dump(y,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "After the data have been processed, we are ready to start the model seletion. In this project, we will use two methods for parameter selection - random search and grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import runtime_path\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# from sklearn.model_selection import RandomizedSearchCV, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the hyper parameters for each model, we first implement random search and grid search.\n",
    "\n",
    "For logistic regression, we use random search to decide the value of C, and wether or not using dual formulation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log regression\n",
    "def lr_search(train_X, train_y, verbose=False):\n",
    "    if verbose:\n",
    "        print('Logistic regression')\n",
    "    clf = LogisticRegression(max_iter=10000, random_state=0, tol=1e-4)\n",
    "    param_dist = {'C': uniform(0.1, 20), 'dual': [True, False]}\n",
    "\n",
    "    # hyper params search\n",
    "    search_iters = 30\n",
    "    random_search = RandomizedSearchCV(\n",
    "        clf, param_distributions=param_dist, n_iter=search_iters,\n",
    "        verbose=False, cv=5)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Staring random search for logistic regression hyper parameters...\")\n",
    "    random_search.fit(train_X, train_y)\n",
    "    if verbose:\n",
    "        print(\"Random search complete\")\n",
    "        print(\"Random search best score: \", random_search.best_score_)\n",
    "        print(\"Random search gives best params as: \", random_search.best_params_)\n",
    "\n",
    "    return random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVM, we use grid search to find type of kernal, value of gamma and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "def svm_search(train_X, train_y, verbose=False):\n",
    "    if verbose:\n",
    "        print('SVM classifier...')\n",
    "    train_X = train_X / train_X.sum(axis = 0) # normalize data\n",
    "\n",
    "    clf = svm.SVC(random_state=0, tol=1e-4, max_iter=10000)\n",
    "    param_dist = {\n",
    "        'gamma': np.logspace(-3,1,5),\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': [0.1,1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "    # hyper params search\n",
    "    search_iters = 30\n",
    "    grid_search = GridSearchCV(\n",
    "        clf, param_grid=param_dist,\n",
    "        verbose=False, cv=5)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Staring grid search for svm hyper parameters...\")\n",
    "    grid_search.fit(train_X, train_y)\n",
    "    if verbose:\n",
    "        print(\"Grid search complete\")\n",
    "        print(\"Grid search best score: \", grid_search.best_score_)\n",
    "        print(\"Grid search gives best params as: \", grid_search.best_params_)\n",
    "\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neural network, we use grid search to find number of hidden units, learning rate and regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "def nn_search(train_X, train_y, verbose=False):\n",
    "    if verbose:\n",
    "        print('Neural Net classifier...')\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(train_X)  \n",
    "    train_X = scaler.transform(train_X)  \n",
    "\n",
    "    clf = MLPClassifier(solver='adam', activation='relu', \n",
    "                        max_iter=10000)\n",
    "\n",
    "    param_dist = {\n",
    "        'hidden_layer_sizes': [(5,),(10,),(15,),(20,)],\n",
    "        'alpha': [1e-2,1e-1,1],\n",
    "        'learning_rate_init': [1e-1, 1, 10]}\n",
    "\n",
    "    # hyper params search\n",
    "    search_iters = 30\n",
    "    grid_search = GridSearchCV(\n",
    "        clf, param_grid=param_dist,\n",
    "        verbose=False, cv=5)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Staring grid search for neural network hyper parameters...\")\n",
    "    grid_search.fit(train_X, train_y)\n",
    "    if verbose:\n",
    "        print(\"Grid search complete\")\n",
    "        print(\"Grid search best score: \", grid_search.best_score_)\n",
    "        print(\"Grid search gives best params as: \", grid_search.best_params_)\n",
    "\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare these 4 models and see who does a better job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_contest(X, y):\n",
    "    # get small data for model selection\n",
    "#     data = Data()\n",
    "#     train_X, train_y = data.get_train_set()\n",
    "#     test_X, test_y = data.get_test_set()\n",
    "#     scaler = StandardScaler()\n",
    "#     train_X = scaler.fit_transform(train_X)\n",
    "#     test_X = scaler.fit_transform(test_X)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    np.random.seed(100)\n",
    "#     para_X = np.random.randint(100, size=(100,28))\n",
    "#     para_y = np.random.randint(2, size = (100,))\n",
    "#     para_X = scaler.fit_transform(para_X)\n",
    "    \n",
    "\n",
    "#     train_X = np.random.randint(100, size=(1000,28))\n",
    "#     train_y = np.random.randint(2, size = (1000,))\n",
    "#     test_X = np.random.randint(20, size=(100,28))\n",
    "#     test_y = np.random.randint(2, size = (100,))\n",
    "#     train_X = scaler.fit_transform(train_X)\n",
    "#     test_X = scaler.fit_transform(test_X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    n = X.shape[0]\n",
    "    P = np.random.permutation(n)\n",
    "    para_X = X[P[:5000],:]\n",
    "    para_y = y[P[:5000]]\n",
    "    train_X = X[P[-10000:],:]\n",
    "    train_y = y[P[-10000:]]\n",
    "    test_X = X[P[:-10000],:]\n",
    "    test_y = y[P[:-10000]]\n",
    "    \n",
    "    para_X = scaler.fit_transform(para_X)\n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.fit_transform(test_X)\n",
    "    \n",
    "    print(para_X.shape)\n",
    "    print(para_y.shape)\n",
    "    print(train_X.shape)\n",
    "    print(train_y.shape)\n",
    "    print(test_X.shape)\n",
    "    print(test_y.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Hyper parameter search for Logistic Regression\n",
    "    lr_params = lr_search(para_X, para_y)\n",
    "    # Hyper parameter search for SVM\n",
    "#     svm_params = svm_search(para_X, para_y)\n",
    "    # Hyper parameter search for Neural Network\n",
    "    nn_params = nn_search(para_X, para_y)\n",
    "    \n",
    "    # Initialize models\n",
    "    nb_model = GaussianNB()\n",
    "    lr_model = LogisticRegression(C=lr_params[\"C\"], dual = lr_params[\"dual\"], \n",
    "                                  max_iter=10000, random_state=0, tol=1e-4)\n",
    "#     svm_model = svm.SVC(C=svm_params['C'], gamma=svm_params['gamma'], kernel=svm_params['kernel'], \n",
    "#                         random_state=0, tol=1e-4, max_iter=10000)\n",
    "    nn_model = MLPClassifier(alpha=nn_params['alpha'], hidden_layer_sizes=nn_params['hidden_layer_sizes'],\n",
    "                             learning_rate_init=nn_params['learning_rate_init'], \n",
    "                             solver='adam', activation='relu', max_iter=10000)\n",
    "    # Train models\n",
    "    nb_model.fit(train_X, train_y)\n",
    "    lr_model.fit(train_X, train_y)\n",
    "#     svm_model.fit(train_X, train_y)\n",
    "    nn_model.fit(train_X, train_y)\n",
    "    \n",
    "#     result = {'NB': nb_model.score(test_X, test_y), 'LR': lr_model.score(test_X, test_y), \n",
    "#               'SVM': svm_model.score(test_X, test_y), 'NN': nn_model.score(test_X, test_y)}\n",
    "        \n",
    "    result = {'NB': nb_model.score(test_X, test_y), 'LR': lr_model.score(test_X, test_y), \n",
    "              'NN': nn_model.score(test_X, test_y)}\n",
    "    return result\n",
    "    pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('X_data.pickle', 'rb') as f_x:\n",
    "    X = pickle.load(f_x)\n",
    "    print(X.shape)\n",
    "    \n",
    "with open('y_data.pickle', 'rb') as f_y:\n",
    "    y = pickle.load(f_y)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_contest(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, ... has the highest accuracy over all models. The difference between each model are very small, indicating that this is the best result we can get from these features. The information revealed by these features are not enough for us to increase our accuracy. Here we use the average recent performance to represent how good a team is, which is a very rough estimate. There are many more factors that will affect the result of a game which we didn't consider.\n",
    "\n",
    "To get a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('X_ad3.pickle', 'rb') as f_x:\n",
    "    X_ad = pickle.load(f_x)\n",
    "    print(X_ad.shape)\n",
    "    \n",
    "with open('y_ad3.pickle', 'rb') as f_y:\n",
    "    y_ad = pickle.load(f_y)\n",
    "    print(y_ad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_both = np.hstack((X,X_ad))\n",
    "# X_both = X_both[~np.isnan(X_both).any(axis=1)]\n",
    "X_both.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_contest(X_both, y_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
